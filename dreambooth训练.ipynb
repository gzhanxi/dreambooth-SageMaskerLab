{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b23194-8c40-47b5-9eea-4e5ff5f87eb1",
   "metadata": {},
   "source": [
    "## Dreambooth Stable Diffusion训练\n",
    "修改自 [bilibili 秋葉aaaki 的 dreambooth autodl 训练脚本](https://github.com/Akegarasu/dreambooth-autodl)\n",
    "修改自 [Nyanko Lepsoni 的 Colab 笔记本](https://colab.research.google.com/drive/17yM4mlPVOFdJE_81oWBz5mXH9cxvhmz8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a0886-58f2-4f6a-a03a-7a1b4e66c688",
   "metadata": {},
   "source": [
    "### 全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1ba7b-81a5-426a-b524-50e490488ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "py310 = sys.executable\n",
    "\n",
    "!$py310 --version\n",
    "PATH = \"/home/studio-lab-user/dreambooth-SageMaskerLab\"\n",
    "%cd $PATH\n",
    "\n",
    "TRAINER = \"train_dreambooth.py\"\n",
    "CONVERTER = \"convert_v2.py\"\n",
    "BACK_CONVERTER = \"back_convert.py\"\n",
    "ACCELERATE_BIN = \"/root/miniconda3/envs/diffusers/bin/accelerate\"\n",
    "\n",
    "SRC_PATH = \"~/tmp/model-sd\"\n",
    "MODEL_NAME = \"./model-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6669cc11-7021-40c8-8fe7-6b56fa53cb6f",
   "metadata": {},
   "source": [
    "### 下载animefull-final-pruned模型及vae.pt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedec61-a295-4bc2-a19d-f85b25d7f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $SRC_PATH\n",
    "!curl -Lo model.ckpt https://huggingface.co/a1079602570/animefull-final-pruned/resolve/main/model-001.ckpt\n",
    "!curl -Lo config.yaml https://huggingface.co/a1079602570/animefull-final-pruned/resolve/main/config.yaml\n",
    "!curl -Lo animevae.pt https://huggingface.co/a1079602570/animefull-final-pruned/resolve/main/animevae.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c319f-521a-46e3-8797-bf7c80db2d3e",
   "metadata": {},
   "source": [
    "### 转换ckpt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220b509-034e-48a7-9163-8161d0835f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这步骤有些慢，没准要等个几分钟\n",
    "vae_arg = f\"--vae_path {SRC_PATH}/animevae.pt\"\n",
    "!$py310 $CONVERTER --checkpoint_path $SRC_PATH/model.ckpt --original_config_file $SRC_PATH/config.yaml $vae_arg --dump_path $MODEL_NAME --scheduler_type ddim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6c96b-95fc-4e6b-9584-1fd6ed889df7",
   "metadata": {},
   "source": [
    "### 配置dreambooth提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec999f-1110-413f-90ad-a8f19d7a70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANCE_PROMPT\n",
    "INSTANCE_PROMPT = \"masterpiece, best quality, bocchitherock 1girl\"\n",
    "INSTANCE_DIR = \"./instance-images\"\n",
    "\n",
    "# class image 设置\n",
    "CLASS_PROMPT = \"masterpiece, best quality, 1girl\"\n",
    "CLASS_NEGATIVE_PROMPT = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"\n",
    "CLASS_DIR = \"./class-images\"\n",
    "\n",
    "# 预览图tag设置\n",
    "SAVE_SAMPLE_PROMPT = \"masterpiece, best quality, bocchitherock 1girl, looking at viewer\"\n",
    "SAVE_SAMPLE_NEGATIVE_PROMPT = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"\n",
    "\n",
    "# 模型保存路径\n",
    "OUTPUT_DIR = \"~/tmp2\"\n",
    "print(f\"[*] 模型将会保存在这个路径 {OUTPUT_DIR}\")\n",
    "!mkdir -p $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d616747-8038-479b-bbb6-a70cdafe8e70",
   "metadata": {},
   "source": [
    "### 训练监控仪表盘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9886be4-6914-492f-a290-03b988749188",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_tensorboard = True \n",
    "use_wandb = False\n",
    "save_weights_to_wandb = False\n",
    "wandb_apikey = \"\"\n",
    "\n",
    "if use_wandb:\n",
    "  if wandb_apikey == \"\":\n",
    "    raise ValueError('Invalid wandb.ai APIKey')\n",
    "  !$py310 -m wandb login $wandb_apikey\n",
    "\n",
    "if use_tensorboard:\n",
    "  !rm -rf /tmp/.tensorboard-info/\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir $OUTPUT_DIR/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38eac99-cbd1-4d97-9f73-dc4c2a62036e",
   "metadata": {},
   "source": [
    "### 配置accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f869b6-e83b-4e41-a6a2-35c03cb8eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ~/.cache/huggingface/accelerate\n",
    "\n",
    "cat > ~/.cache/huggingface/accelerate/default_config.yaml <<- EOM\n",
    "compute_environment: LOCAL_MACHINE\n",
    "deepspeed_config: {}\n",
    "distributed_type: 'NO'\n",
    "downcast_bf16: 'no'\n",
    "fsdp_config: {}\n",
    "machine_rank: 0\n",
    "main_process_ip: null\n",
    "main_process_port: null\n",
    "main_training_function: main\n",
    "mixed_precision: fp16\n",
    "num_machines: 1\n",
    "num_processes: 1\n",
    "use_cpu: false\n",
    "EOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c93f39-9b1b-4d48-bfce-55a2fcd6e150",
   "metadata": {},
   "source": [
    "### 设置训练参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a133356-aaf1-4661-9507-1bc0f5b19ea9",
   "metadata": {},
   "source": [
    "### max_train_steps\n",
    "训练步数\n",
    "\n",
    "### learning_rate\n",
    "学习率\n",
    "这里设置的5e-6是科学计数法的(5乘以10的-6次方)。一般就用这个值就可以了，有时候这个默认值有点大，可以小一些比如3e-6。如果你还是觉得太大可以缩小到1e-6、甚至是5e-7等等。\n",
    "\n",
    "### lr_scheduler\n",
    "学习率调整策略\n",
    "一般lr_scheduler就用cosine、cosine_with_restarts就可以了。\n",
    "想了解更多关于lr_scheduler可以看看这个[知乎](https://www.zhihu.com/question/315772308/answer/2384958925)\n",
    "\n",
    "### batch_size\n",
    "一般是1。我推荐不要超过3。调整batch_size需要同时调整学习率\n",
    "详情参考bilibili 秋葉aaaki的视频[BV1A8411775m](https://www.bilibili.com/video/BV1A8411775m/)\n",
    "\n",
    "### num_class_images\n",
    "class image的数量。如果class-images文件夹内的图片数量小于这个值，则会AI自动生成一些图片。\n",
    "如果关闭了下面的with_prior_preservation，那么这个参数就没用了。\n",
    "\n",
    "### with_prior_preservation\n",
    "关闭了这个参数以后，训练将不会再用class images，变为native training。训练画风需要关闭\n",
    "\n",
    "更深入的细节可以参考这个[stable-diffusion-book](https://stable-diffusion-book.vercel.app/train/DreamBooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c145977-4e4b-440a-8558-21cbf2f855ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常用参数\n",
    "## 最大训练步数\n",
    "max_train_steps = 3000\n",
    "## 学习率调整\n",
    "learning_rate = 5e-6\n",
    "## 学习率调整策略\n",
    "## [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"cosine_with_restarts_mod\", \"cosine_mod\"]\n",
    "lr_scheduler = \"cosine_with_restarts\"\n",
    "lr_warmup_steps = 100\n",
    "# batch_size\n",
    "train_batch_size = 1\n",
    "# class_images 数量\n",
    "num_class_images = 20\n",
    "\n",
    "with_prior_preservation = True\n",
    "\n",
    "# 从文件名读取 prompt\n",
    "read_prompt_from_filename = False\n",
    "# 从 txt 读取prompt\n",
    "read_prompt_from_txt = False\n",
    "append_prompt = \"instance\"\n",
    "# 保存间隔\n",
    "save_interval = 500\n",
    "# 使用deepdanbooru\n",
    "use_deepdanbooru = False\n",
    "\n",
    "# 高级参数\n",
    "resolution = 512\n",
    "gradient_accumulation_steps = 1\n",
    "seed = 1337\n",
    "log_interval = 10\n",
    "clip_skip = 1\n",
    "sample_batch_size = 4\n",
    "prior_loss_weight = 1.0\n",
    "use_aspect_ratio_bucket = False\n",
    "scale_lr = False\n",
    "scale_lr_sqrt = False\n",
    "gradient_checkpointing = True\n",
    "pad_tokens = False\n",
    "debug_arb = False\n",
    "debug_prompt = False\n",
    "use_ema = False\n",
    "train_text_encoder = False\n",
    "#only works with _mod scheduler\n",
    "restart_cycle = 1\n",
    "last_epoch = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6044329-71e1-49ba-95a3-53ba4991008a",
   "metadata": {},
   "source": [
    "如果是继续训练就更改这个路径到想继续训练的模型文件夹然后运行这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de80ab-1485-4143-92b4-e9019f41bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"{OUTPUT_DIR}/checkpoint_last\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f542f3-73e4-4ea7-90cf-eb0aa2b80a6f",
   "metadata": {},
   "source": [
    "### 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7b2e6-c158-483a-ac02-c7819d295458",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_arg = \"--use_ema\" if use_ema else \"\"\n",
    "da_arg = \"--debug_arb\" if debug_arb else \"\"\n",
    "db_arg = \"--debug_prompt\" if debug_prompt else \"\"\n",
    "pd_arg = \"--pad_tokens\" if pad_tokens else \"\"\n",
    "gdc_arg = \"--gradient_checkpointing\" if gradient_checkpointing else \"\"\n",
    "dp_arg = \"--deepdanbooru\" if use_deepdanbooru else \"\" \n",
    "scale_lr_arg = \"--scale_lr\" if scale_lr else \"\"\n",
    "wandb_arg = \"--wandb\" if use_wandb else \"\"\n",
    "extra_prompt_arg = \"--read_prompt_txt\" if read_prompt_from_txt else \"\"\n",
    "arb_arg = \"--use_aspect_ratio_bucket\" if use_aspect_ratio_bucket else \"\"\n",
    "tte_arg = \"--train_text_encoder\" if train_text_encoder else \"\"\n",
    "ppl_arg = f\"--with_prior_preservation --prior_loss_weight={prior_loss_weight}\" if with_prior_preservation else \"\"\n",
    "\n",
    "if scale_lr_sqrt:\n",
    "  scale_lr_arg = \"--scale_lr_sqrt\"\n",
    "\n",
    "if read_prompt_from_filename:\n",
    "  extra_prompt_arg = \"--read_prompt_filename\"\n",
    "\n",
    "if save_weights_to_wandb:\n",
    "  wandb_arg = \"--wandb --wandb_artifact\"\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "%cd $PATH\n",
    "!mkdir -p $OUTPUT_DIR\n",
    "\n",
    "!$ACCELERATE_BIN launch $TRAINER \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --class_data_dir=$CLASS_DIR \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --instance_prompt=\"{INSTANCE_PROMPT}\" \\\n",
    "  --class_prompt=\"{CLASS_PROMPT}\" \\\n",
    "  --class_negative_prompt=\"{CLASS_NEGATIVE_PROMPT}\" \\\n",
    "  --save_sample_prompt=\"{SAVE_SAMPLE_PROMPT}\" \\\n",
    "  --save_sample_negative_prompt=\"{SAVE_SAMPLE_NEGATIVE_PROMPT}\" \\\n",
    "  --seed=$seed \\\n",
    "  --resolution=$resolution \\\n",
    "  --train_batch_size=$train_batch_size \\\n",
    "  --gradient_accumulation_steps=$gradient_accumulation_steps \\\n",
    "  --learning_rate=$learning_rate \\\n",
    "  --lr_scheduler=$lr_scheduler \\\n",
    "  --lr_warmup_steps=$lr_warmup_steps \\\n",
    "  --num_class_images=$num_class_images \\\n",
    "  --sample_batch_size=$sample_batch_size \\\n",
    "  --max_train_steps=$max_train_steps \\\n",
    "  --save_interval=$save_interval \\\n",
    "  --log_interval=$log_interval \\\n",
    "  --clip_skip $clip_skip \\\n",
    "  --num_cycle=$restart_cycle \\\n",
    "  --last_epoch=$last_epoch \\\n",
    "  --append_prompt=$append_prompt \\\n",
    "  --use_8bit_adam $da_arg $db_arg $ema_arg --xformers \\\n",
    "  $ppl_arg $wandb_arg $extra_prompt_arg $gdc_arg $arb_arg $tte_arg $scale_lr_arg $dp_arg $pd_arg\n",
    "\n",
    "# disabled: --not_cache_latents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d53e5f-b123-4b6c-9f46-e775abc546fe",
   "metadata": {},
   "source": [
    "### 训练效果测试\n",
    "**生成效果与本地webui不太一样，仅供参考**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099683f1-d927-4f41-a632-8f5a9c483f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "use_checkpoint = 'checkpoint_last'\n",
    "ckpt_model_path = os.path.join(OUTPUT_DIR, use_checkpoint)\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(ckpt_model_path, torch_dtype=torch.float16).to(\"cuda\")\n",
    "g_cuda = None\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def inference(prompt, negative_prompt, num_samples, height=512, width=512, num_inference_steps=50, guidance_scale=7.5):\n",
    "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
    "        return pipe(\n",
    "                prompt, height=int(height), width=int(width),\n",
    "                negative_prompt=negative_prompt,\n",
    "                num_images_per_prompt=int(num_samples),\n",
    "                num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n",
    "                generator=g_cuda\n",
    "            ).images\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            prompt = gr.Textbox(label=\"tag\", value=\"masterpiece, best quality,\")\n",
    "            negative_prompt = gr.Textbox(label=\"负面tag\", value=\"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\")\n",
    "            num_inference_steps = gr.Slider(label=\"Steps\", value=28)\n",
    "            with gr.Row():\n",
    "                width = gr.Slider(minimum=64, maximum=2048, step=64, label=\"宽\", value=512)\n",
    "                height = gr.Slider(minimum=64, maximum=2048, step=64, label=\"高\", value=512)\n",
    "            with gr.Row():\n",
    "                num_samples = gr.Number(label=\"批量\", value=1)\n",
    "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=7)\n",
    "\n",
    "        with gr.Column():\n",
    "            run = gr.Button(value=\"生成\")\n",
    "            gallery = gr.Gallery()\n",
    "\n",
    "    run.click(inference, inputs=[prompt, negative_prompt, num_samples, height, width, num_inference_steps, guidance_scale], outputs=gallery)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb7a06-7fe0-44ed-964b-d6b2b2fcd61b",
   "metadata": {},
   "source": [
    "## 转换训练好的模型到ckpt文件\n",
    "\n",
    "这里需要你修改model_folder_name, 比如\n",
    "checkpoint_1000\n",
    "checkpoint_2000\n",
    "想转换哪个模型写哪个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995aa7e-ea80-402d-a172-2701847c2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_name = \"checkpoint_last\"\n",
    "convert_model_path = f\"{OUTPUT_DIR}/{model_folder_name}\"\n",
    "ckpt_path = f'{OUTPUT_DIR}/model.ckpt'\n",
    "save_half = False\n",
    "use_alt = False\n",
    "\n",
    "ckpt_convert_half_arg = \"--half\" if save_half else \"\"\n",
    "back_converter_arg = \"back_convert_alt.py\" if use_alt else \"back_convert.py\"\n",
    "\n",
    "!$py310 $back_converter_arg --model_path $convert_model_path --checkpoint_path $ckpt_path $ckpt_convert_half_arg\n",
    "print(f\"[*] 转换的模型保存在如下路径 {ckpt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
